---
title: "COPASProfiler"
output: 
  html_document: 
      fig_caption: yes
      toc: yes
      toc_depth: 3
      toc_float: yes
---

# COPASProfiler Package Description

COPASProfiler is an R package that can view, filter, classify and analyze COPAS Large Particle Flow Cytometer. Below is a tutorial on how to install the package, get training data and how to use the functions and pipelines. 

# COPASProfiler Model Creation pipeline

## Introduction 

The COPAS Large Particle Flow Cytometer (COPAS FC) allows fluorescence screening of a large number of worms in a short time. However, the output of machine is hard to interpret. Worms that go in the COPAS FC can go in straight or turned over themselves. If the worm is turned on itself, that will overlap the florescence expression of its body and will create a different expression pattern in the data compared to a worm that went in straight. The COPASProfiler package was created to help visualize the objects better. This tutorial is intended to teach users how to create their own SVM model to distinguish good worms (Worms that went in straight) from other unwanted objects. 

## How to get the package 

You can access the package's github through this link: https://github.com/ksnksa/COPASProfiler
You can also run this code to directly download the package in Rstudio.
```{r , eval=FALSE}
devtools::install_github("ksnksa/COPASProfiler/COPASProfiler")
```
To load the package, simply run the following code. 
```{r, eval=FALSE}
library("COPASProfiler")
```

## What data set to use 

The COPAS FC outputs more than one file for each run. (NameOfRun).txt which contains the general information of all the objects and four (NameOfRun)_ch#_prf.txt files (the # goes from 0 to 3) which contain the data from each channel. Weâ€™ll only be using the last four files. If you just want to follow this example, the tutorial loads the example files directly from our github repository. 

## How to get the annotated IDs 

We also use another csv file that contains annotated objects and their IDs. We'll be using this file to create our model. To create your own annotation, you can go to our [website](https://wormbuilder.dev/WormProfiler/).
The website allows you to visualize the object's channel data. 

![](https://raw.githubusercontent.com/ksnksa/WormSorter/main/WormProfiler.PNG)

1: Load the four channel data files then press submit.  2: The output plot of the selected object. 3: Here you can select which object ID you'd like to view. 4: You can check which channel you'd like to be in the plot. 5: The swipe right and swipe left buttons allow you to annotate the objects. Swiping right means annotating this object as a good worm, and swiping left means annotating this object as a bad worm. After annotating any number of objects, a button will pop up to download the annotated IDs. 


![](https://raw.githubusercontent.com/ksnksa/WormSorter/main/Download.PNG)

## Running the pipeline 

```{r, warning=FALSE, message=FALSE,eval=FALSE}

##Loading the libraries
library(ggplot2) #
library(dplyr) #
library(scales) #
library(WormSorter) #
library(kernlab) #
library(jmotif) #
```

### Loading the data 

In this example, we used a sample data set generated by the [Laboratory of Synthetic Genome Biology](https://syngenbio.kaust.edu.sa/). You can run the following code to use the same data set and annotated IDs files we're using. Ch0D, Ch1D, Ch2D, Ch3D, are the paths for each channel profile. GoodIDD is the path to the annotated IDs csv file.

```{r,eval=FALSE}
#Channel directory taken from the WormSorter github
#When using your own data simply change these links to the file directory of the channels. 
Ch0D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch0_prf.txt'
Ch1D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch1_prf.txt'
Ch2D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch2_prf.txt'
Ch3D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch3_prf.txt'
#CSV file containing the levels (or annotation) for each worm in our training set. 
GoodIDD <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/GoodIDsNew.csv'
```


### Setting up the parameters 

The following parameters can be changed to suit the user's needs. MaxAmp, MinLength and MaxLength are parameters that control the initial filtering in this pipeline. MaxAmp is simply the maximum amplitude that an object can have. MinLength and MaxLength determine the minimum and maximum time of flight for each object. The purpose of this filtering, is to remove unwanted bubbles or artifacts. ChannelToCluster determines which channel the pipeline will work with. 1 is for Channel 0, 2 for Channel 1 and so on. Stage determines what worm stage the program will cluster. The package assigns the stage of each worm depending on the time of travel. The thresholds for the time of travel were taken from experimental data generated by the SGB lab [ref here]. When using your own data, the thresholds might differ depending on your COPAS FC aquisiton parameters. 

```{r, warning=FALSE, message=FALSE,eval=FALSE}
#Setting up the parameters we need for the analysis
# Max amplitude an object can have 
# Anything more will be filitered out
MaxAmp <- 35000
# Minimum and maximum time of flight for each object
MinLength <- 40
MaxLength <- 900
# Which channel the pipeline will work on 
# 1 is for Channel 0, 2 is for Channel 1 
# 3 is for Channel 2, 4 is for Channel 3
ChannelNumber <- 1
```

### Example run 

#### Loading the training set

First we load up the channel data and apply an initial filter. Then we load up the annotated IDs csv file and create a variable that has the data for the worms that were annotated. 

```{r, warning=FALSE, message=FALSE,eval=FALSE}
# The ReadChannel function simply takes in the channel directories and returns a list with all
# the channels data.
channellist <- ReadChannel(Ch0D,Ch1D,Ch2D,Ch3D)
# The PreProcessData function removes profiles outside of the provided thresholds, removes trailing zeros for each profile
# applies the PAA function to uniform the length, and applies z-score normalization on the Y axis. 
ModData <- PreProcessData(channellist, MinLength,MaxLength,MaxAmp, ChannelNumber)
# The CreateTrainingSetIDs function translates the annotated IDs csv 
# file to the data we have and gives out the index of the worms that are annotated.
WormIDs <- CreateTrainingSetIDs(ModData,GoodIDD)
```

#### Option 1: Model performance on the same individual set 

##### Input to dictate how much of the training set will be the prediction set 
##### then run the model on the prediciton set and show results

#### Option 2: Loading a prediction set 

The same parameters will be used on the prediction set as previously stated. 

```{r,eval=FALSE}
#Channel directory taken from the WormSorter github
#When using your own data simply change these links to the file directory of the channels. 
Ch0D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch0_prf.txt'
Ch1D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch1_prf.txt'
Ch2D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch2_prf.txt'
Ch3D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch3_prf.txt'
#CSV file containing the levels (or annotation) for each worm in our training set. 
GoodIDD <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/GoodIDsNew.csv'
```

```{r, warning=FALSE, message=FALSE,eval=FALSE}
#Setting up the parameters we need for the analysis
# Max amplitude an object can have 
# Anything more will be filitered out
MaxAmp <- 35000
# Minimum and maximum time of flight for each object
MinLength <- 40
MaxLength <- 900
# Which channel the pipeline will work on 
# 1 is for Channel 0, 2 is for Channel 1 
# 3 is for Channel 2, 4 is for Channel 3
ChannelNumber <- 1
```

```{r, warning=FALSE, message=FALSE,eval=FALSE}
# The ReadChannel function simply takes in the channel directories and returns a list with all
# the channels data.
channellist <- ReadChannel(Ch0D,Ch1D,Ch2D,Ch3D)
# The PreProcessData function removes profiles outside of the provided thresholds, removes trailing zeros for each profile
# applies the PAA function to uniform the length, and applies z-score normalization on the Y axis. 
ModData <- PreProcessData(channellist, MinLength,MaxLength,MaxAmp, ChannelNumber)
# The CreateTrainingSetIDs function translates the annotated IDs csv 
# file to the data we have and gives out the index of the worms that are annotated.
WormIDs <- CreateTrainingSetIDs(ModData,GoodIDD)
```

#### Model performance on the other prediction set  


#####optimizing model param 
```{r,eval=FALSE}
library(mlr)
```


```{r,eval=FALSE}
TSet1123$Factor <- as.factor(TSet1123$Factor)
ksvm_task = makeClassifTask(data = TSet1123, target = "Factor")
discrete_ps = makeParamSet(
    makeDiscreteParam("C", values = c(2 %o% 10^(-5:5)) ),
    makeDiscreteParam("sigma", values = c(2 %o% 10^(-5:5)) )
)
print(discrete_ps)

ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 3L)

#res = tuneParams("classif.ksvm", ksvm_task , rdesc, par.set = discrete_ps, control = ctrl)
# CHANGE: Use accuracy as measure instead of MSE, more appropriate for classification
res = tuneParams("classif.ksvm", ksvm_task , rdesc, measures=acc, par.set = discrete_ps, control = ctrl)
print(res)
```


######make model and save it 

```{r,eval=FALSE}
Listhe <- RandomTrainingSet(ModData3, WormIDs1110, round(length(WormIDs1110[[1]]) - 1),round(length(WormIDs1110[[2]]) - 1))
TSet <- Listhe[[1]]
PSet <- Listhe[[2]]
TSet1110 <- TSet
#Model1123 <- ksvm(as.matrix(TSet[,1:50]), as.factor(TSet[,51]),type = 'C-svc', kernel= "laplacedot",C=3,kpar = list(sigma = 1),scaled=FALSE, cross = 5)
```


###### trying all the kernels

```{r,eval=FALSE}
Model1123 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "rbfdot",C=200,kpar = list(sigma = 0.002),scaled=FALSE, cross = 10)
Model1123.2 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "polydot",C=3,scaled=FALSE, cross = 5)
Model1123.3 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "vanilladot",C=3,scaled=FALSE, cross = 5)
Model1123.4 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "tanhdot",C=3,scaled=FALSE, cross = 5)
Model1123.5 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "laplacedot",C=200,kpar = list(sigma = 0.002),scaled=FALSE, cross = 5)
Model1123.6 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "besseldot",C=3,scaled=FALSE, cross = 5)
Model1123.7 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "anovadot",C=3,scaled=FALSE, cross = 5)
```


###### Model 1111 on remaining sets 

```{r,eval=FALSE}
pred1 <- predict(Model1111,TSet1110[,1:50])
#sum(pred1 == ModDataTest2[,51]) / nrow(ModDataTest2)
Positive <- rownames(TSet1110[which(pred1==2),])
TP <- length(which(Positive %in% rownames(TSet1110[which(TSet1110$Factor == 2),]) ))
Negative <- rownames(TSet1110[which(pred1==1),])
TN <- length(which(Negative %in% rownames(TSet1110[which(TSet1110$Factor == 1),]) ))
 (TP + TN) / (length(Positive) + length(Negative))
# Accuracy after the filtering is  0.8921283 
TP/length(Positive)
```

# Transgene Plotter Pipeline

## Introduction 

The purpose of this tutorial is to create an easy to use pipeline to plot the fluorescence of _C. elegans_. The COPAS worm sorter provides a txt file based output that contains the summary of all the objects that were screened. The user then has to manually copy the information of the desired objects and plot them using third party plotting programs. The functions in the WormSorter package allow for plotting of individual runs or strains or creating a summary plot containing different runs or strains. The functions can also take in an Annotated IDs file to remove the worms that are annotated as bad worms. You can create your own annotated IDs file by visiting our [website](https://wormbuilder.dev/WormProfiler/).


## Libraries

```{r,eval=FALSE}
## Loading the required libraries 
library(ggplot2)
library(dplyr)
library(reshape2)
library(WormSorter)
library(plotly)
library(utils)
library(e1071)
library(prospectr)
library(reshape)
library(tibble)
library(scales)
library(stringr)
library(pracma)
library(jmotif)
library(kernlab)
```

## Running classification (Optional) 

```{r, eval=FALSE}
ModelDirectory <- '/srv/share/Transgene plotter/TestData/Model.R'
DataDirectory <- '/srv/share/Transgene plotter/TestData/1124.2C red 600 green 500_prf.txt'
#Minimum time of flight
MinTOF <- 51
#Maximum time of flight
MaxTOF <- 800
#Maximum optical density amplitude 
MaxPeak <- 35000
# 'Fullfile' means the input data is the unsplit COPAS files, or 'FirstChannel'
DataType <- 'FullFile'
```

```{r, eval=FALSE}
AnnotatedIDs <- RunClassification(DataDirectory,ModelDirectory,MaxPeak,MinTOF,MaxTOF,TypeOfData = DataType)
```


## Plotting One Strain/Run

The SummaryPlot function takes in one run summary file (in .txt format), the name of the strain/run and the desired fluorescence channel to return six plots. The function groups up the objects into five groups based on their time of flight and plots them individually. The final plot is the summary plot containing all five groups. 


### Parameters

The data used here was generated by the [Laboratory of Synthetic Genome Biology](https://syngenbio.kaust.edu.sa/). You can acess these data and download them at this [github](https://github.com/ksnksa/WormSorter). 
The minimum parameters needed for the SummaryPlot function are FileDirectory, NameofStrain and Channel. Note: The input for these parameters must be in between ' '. 

```{r, eval=FALSE}
# File directory (the summary txt file output from the COPAS worm sorter)
FileDirectory <-'/srv/share/Transgene plotter/TestData/1124.2C red 600 green 500_prf.txt'
# Name of the strain we're working with 
NameofStrain <- '"Data Set Name"'
#Which channel to plot, G is for green, Y is for yellow and R is for red 
Channel <- 'R'
#Measure: 'I' to plot the integral, 'H'to plot the maximum peak
MeasureType <- 'H'
#Scale: 'Normal' is the default. 'Log2' and 'Log10' change the scaling of the Y axis to logarithmic. 
ScaleType <- 'Normal'
#DataType: Default is 'Summary' which takes in the summary output file from the COPAS (usually ends in _prf.txt)
#'Fullfile' means the input data is the unsplit COPAS files 
DataType <- 'FullFile'
#Maximum Fluorescence accepted. Any more than provided number will be filtered out. 
FluoMax <- 50000 #Input 'NA' to skip this step
```

### Running The Function 

```{r, eval=FALSE}
P <- SummaryPlot(FileDirectory,NameofStrain,Channel,Measure = MeasureType,
                 Scale = ScaleType, TypeOfData = DataType, FluoThreshold = FluoMax)
P[[1]] 
P[[2]]
P[[3]]
P[[4]]
P[[5]]
P[[6]]
P[[7]]
```


### Remove Specific Worms From The Data Set

The function can also take in another parameter (AnnotatedIDsDirectory) to remove specific objects from the data set before plotting. Using the [COPASWormTools](https://wormbuilder.dev/WormProfiler/), we can download the annotated IDs file and provide the directory to the function. The function will then remove the annotated 'bad' worms before plotting the strain/run. 

```{r, eval=FALSE}
P <- SummaryPlot(FileDirectory,NameofStrain,Channel,Measure = MeasureType,
                 Scale = ScaleType,WormIDs = AnnotatedIDs, TypeOfData = DataType, FluoThreshold = FluoMax)
P[[1]] 
P[[2]]
P[[3]]
P[[4]]
P[[5]]
P[[6]]
P[[7]]
```

### Running Custom Ranges 

The user can also specify their own set of ranges. 

```{r, eval=FALSE}
#The TOF groups range (Default is 51-75, 75-150,150-225,225-500,500-800)
TOFRanges <- c(51,500,550,600,900,1000)
```

Running the function with the new parameter. 

```{r, eval=FALSE}
P <- SummaryPlot(FileDirectory,NameofStrain,Channel,Measure = MeasureType,Scale = ScaleType
                 ,WormIDs = AnnotatedIDs, TypeOfData = DataType,Ranges = TOFRanges)
P[[1]] 
P[[2]]
P[[3]]
P[[4]]
P[[5]]
P[[6]]
P[[7]]
```

We can clearly see that this set of plots had less objects in each group compared to the first set. 


## Plotting Multiple Strains/Runs 

The function SummaryPlots - which should not be confused by SummaryPlot - takes in multiple files and names to provide a boxplot of all the provided runs/strains. 


### Parameters 

The parameters in this function are similar to the one above. The only difference is that FileDirectories and Names can take in more than one input. Note: If using more than one input the format for FileDirectories is -> c('File Directory 1', 'File Directory 2', 'File Directory 3',...) and so on. The Names parameter also follows the same format. The Measure parameter dictates what data is plotted. The default is 'I' which plots the integral of each object. The Scale parameter allows the user to change the Y axis scale from the default 'Normal' to log scales by using the parameters 'Log2' and 'Log10'. 

```{r, eval=FALSE}
FileDirectories <- c('/srv/share/Transgene plotter/TestData/1116.1C red 500 green 600 gain 2.txt',
                    '/srv/share/Transgene plotter/TestData/1123.2C red 500 green 600 gain 2.txt')
# In order of directories
Names <- c('1116.1C',
           '1123.2C')
#Which channel to plot, G is for green, Y is for yellow and R is for red 
FluorescenceChannel <- 'G'
#Measure: 'I' to plot the integral, 'H'to plot the maximum peak
MeasureType <- 'H'
#Scale: 'Normal' is the default. 'Log2' and 'Log10' change the scaling of the Y axis to logarithmic. 
ScaleType <- 'Normal'
#DataType: Default is 'Summary' which takes in the summary output file from the COPAS (usually ends in _prf.txt)
#'Fullfile' means the input data is the unsplit COPAS files 
DataType <- 'Summary'
#Maximum Fluorescence accepted. Any more than provided number will be filtered out. 
FluoMax <- 50000 #Input 'NA' to skip this step
```



### Running The Function 

```{r, eval=FALSE}
P <- SummaryPlots(FileDirectories,Names,FluorescenceChannel, 
                  Measure = MeasureType,Scale = ScaleType, TypeOfData = DataType, FluoThreshold = FluoMax)
P[[1]]
P[[2]]
P[[3]]
P[[4]]
P[[5]]
P[[6]]
P[[7]]
```

## Running Classification on multiple files (Takes a long time) 
Changing the Classify input to anything other than 'NA' will perform classification on each file before plotting.

```{r, eval=FALSE}
#Classify: default is 'NA', assigning any other input will perform classification using the following model 
ClassifyInput <- 'Y'
ModelDirectory <- '/srv/share/Transgene plotter/TestData/Model.R'
# If the file type is "Summary", you must include the directory of the first channel in the same order as the summary files
FileDirectoryFirstChannel <- c('/srv/share/Transgene plotter/TestData/1116.1C red 500 green 600 gain 2_ch0_prf.txt',
                    '/srv/share/Transgene plotter/TestData/1123.2C red 500 green 600 gain 2_ch0_prf.txt')
```

```{r, eval=FALSE}
P <- SummaryPlots(FileDirectories,Names,FluorescenceChannel, FirstChannelDirectories = FileDirectoryFirstChannel,
                  Measure = MeasureType,Scale = ScaleType,TypeOfData = DataType,Classify =ClassifyInput,
                 ModelDirectory = ModelDirectory)
P[[1]]
P[[2]]
P[[3]]
P[[4]]
P[[5]]
P[[6]]
P[[7]]
```

