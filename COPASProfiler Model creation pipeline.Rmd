---
title: "Model Creation Pipeline"
author: "Khlifa Alnaim"
date: "4/25/2022"
output: html_document
---


# Introduction 

The COPAS Large Particle Flow Cytometer (COPAS FC) allows fluorescence screening of a large number of worms in a short time. However, the output of machine is hard to interpret. Worms that go in the COPAS FC can go in straight or turned over themselves. If the worm is turned on itself, that will overlap the florescence expression of its body and will create a different expression pattern in the data compared to a worm that went in straight. The COPASProfiler package was created to help visualize the objects better. This tutorial is intended to teach users how to create their own SVM model to distinguish good worms (Worms that went in straight) from other unwanted objects. 

# How to get the package 

You can access the package's github through this link: https://github.com/ksnksa/WormSorter
You can also run this code to directly download the package in Rstudio.
```{r , eval=FALSE}
devtools::install_github("ksnksa/WormSorter/WormSorter")
```
To load the package, simply run the following code. 
```{r, eval=FALSE}
library("WormSorter")
```

# What data set to use 

The COPAS FC outputs more than one file for each run. (NameOfRun).txt which contains the general information of all the objects and four (NameOfRun)_ch#_prf.txt files (the # goes from 0 to 3) which contain the data from each channel. Weâ€™ll only be using the last four files. If you just want to follow this example, the tutorial loads the example files directly from our github repository. 

# How to get the annotated IDs 

We also use another csv file that contains annotated objects and their IDs. We'll be using this file to create our model. To create your own annotation, you can go to our [website](https://wormbuilder.dev/WormProfiler/).
The website allows you to visualize the object's channel data. 

![](https://raw.githubusercontent.com/ksnksa/WormSorter/main/WormProfiler.PNG)

1: Load the four channel data files then press submit.  2: The output plot of the selected object. 3: Here you can select which object ID you'd like to view. 4: You can check which channel you'd like to be in the plot. 5: The swipe right and swipe left buttons allow you to annotate the objects. Swiping right means annotating this object as a good worm, and swiping left means annotating this object as a bad worm. After annotating any number of objects, a button will pop up to download the annotated IDs. 


![](https://raw.githubusercontent.com/ksnksa/WormSorter/main/Download.PNG)

# Running the pipeline 

```{r, warning=FALSE, message=FALSE,eval=FALSE}

##Loading the libraries
library(ggplot2) #
library(dplyr) #
library(scales) #
library(WormSorter) #
library(kernlab) #
library(jmotif) #
#library(reshape)

#library(utils)
#library(reshape)

#library(tibble)

#library(BBmisc)
#library(pracma)
```

## Loading the data 

In this example, we used a sample data set generated by the [Laboratory of Synthetic Genome Biology](https://syngenbio.kaust.edu.sa/). You can run the following code to use the same data set and annotated IDs files we're using. Ch0D, Ch1D, Ch2D, Ch3D, are the paths for each channel profile. GoodIDD is the path to the annotated IDs csv file.

```{r,eval=FALSE}
#Channel directory taken from the WormSorter github
#When using your own data simply change these links to the file directory of the channels. 
Ch0D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch0_prf.txt'
Ch1D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch1_prf.txt'
Ch2D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch2_prf.txt'
Ch3D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch3_prf.txt'
#CSV file containing the levels (or annotation) for each worm in our training set. 
GoodIDD <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/GoodIDsNew.csv'
```


## Setting up the parameters 

The following parameters can be changed to suit the user's needs. MaxAmp, MinLength and MaxLength are parameters that control the initial filtering in this pipeline. MaxAmp is simply the maximum amplitude that an object can have. MinLength and MaxLength determine the minimum and maximum time of flight for each object. The purpose of this filtering, is to remove unwanted bubbles or artifacts. ChannelToCluster determines which channel the pipeline will work with. 1 is for Channel 0, 2 for Channel 1 and so on. Stage determines what worm stage the program will cluster. The package assigns the stage of each worm depending on the time of travel. The thresholds for the time of travel were taken from experimental data generated by the SGB lab [ref here]. When using your own data, the thresholds might differ depending on your COPAS FC aquisiton parameters. 

```{r, warning=FALSE, message=FALSE,eval=FALSE}
#Setting up the parameters we need for the analysis
# Max amplitude an object can have 
# Anything more will be filitered out
MaxAmp <- 35000
# Minimum and maximum time of flight for each object
MinLength <- 40
MaxLength <- 900
# Which channel the pipeline will work on 
# 1 is for Channel 0, 2 is for Channel 1 
# 3 is for Channel 2, 4 is for Channel 3
ChannelNumber <- 1
```

## Example run 

### Loading the training set

First we load up the channel data and apply an initial filter. Then we load up the annotated IDs csv file and create a variable that has the data for the worms that were annotated. 

```{r, warning=FALSE, message=FALSE,eval=FALSE}
# The ReadChannel function simply takes in the channel directories and returns a list with all
# the channels data.
channellist <- ReadChannel(Ch0D,Ch1D,Ch2D,Ch3D)
# The PreProcessData function removes profiles outside of the provided thresholds, removes trailing zeros for each profile
# applies the PAA function to uniform the length, and applies z-score normalization on the Y axis. 
ModData <- PreProcessData(channellist, MinLength,MaxLength,MaxAmp, ChannelNumber)
# The CreateTrainingSetIDs function translates the annotated IDs csv 
# file to the data we have and gives out the index of the worms that are annotated.
WormIDs <- CreateTrainingSetIDs(ModData,GoodIDD)
```

### Option 1: Model performance on the same individual set 

# Input to dictate how much of the training set will be the prediction set 
# then run the model on the prediciton set and show results

### Option 2: Loading a prediction set 

The same parameters will be used on the prediction set as previously stated. 

```{r,eval=FALSE}
#Channel directory taken from the WormSorter github
#When using your own data simply change these links to the file directory of the channels. 
Ch0D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch0_prf.txt'
Ch1D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch1_prf.txt'
Ch2D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch2_prf.txt'
Ch3D <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/n2_profil_ch3_prf.txt'
#CSV file containing the levels (or annotation) for each worm in our training set. 
GoodIDD <- 'https://raw.githubusercontent.com/ksnksa/WormSorter/main/data/N2/GoodIDsNew.csv'
```

```{r, warning=FALSE, message=FALSE,eval=FALSE}
#Setting up the parameters we need for the analysis
# Max amplitude an object can have 
# Anything more will be filitered out
MaxAmp <- 35000
# Minimum and maximum time of flight for each object
MinLength <- 40
MaxLength <- 900
# Which channel the pipeline will work on 
# 1 is for Channel 0, 2 is for Channel 1 
# 3 is for Channel 2, 4 is for Channel 3
ChannelNumber <- 1
```

```{r, warning=FALSE, message=FALSE,eval=FALSE}
# The ReadChannel function simply takes in the channel directories and returns a list with all
# the channels data.
channellist <- ReadChannel(Ch0D,Ch1D,Ch2D,Ch3D)
# The PreProcessData function removes profiles outside of the provided thresholds, removes trailing zeros for each profile
# applies the PAA function to uniform the length, and applies z-score normalization on the Y axis. 
ModData <- PreProcessData(channellist, MinLength,MaxLength,MaxAmp, ChannelNumber)
# The CreateTrainingSetIDs function translates the annotated IDs csv 
# file to the data we have and gives out the index of the worms that are annotated.
WormIDs <- CreateTrainingSetIDs(ModData,GoodIDD)
```

### Model performance on the other prediction set  


#optimizing model param 
```{r,eval=FALSE}
library(mlr)
```


```{r,eval=FALSE}
TSet1123$Factor <- as.factor(TSet1123$Factor)
ksvm_task = makeClassifTask(data = TSet1123, target = "Factor")
discrete_ps = makeParamSet(
    makeDiscreteParam("C", values = c(2 %o% 10^(-5:5)) ),
    makeDiscreteParam("sigma", values = c(2 %o% 10^(-5:5)) )
)
print(discrete_ps)

ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 3L)

#res = tuneParams("classif.ksvm", ksvm_task , rdesc, par.set = discrete_ps, control = ctrl)
# CHANGE: Use accuracy as measure instead of MSE, more appropriate for classification
res = tuneParams("classif.ksvm", ksvm_task , rdesc, measures=acc, par.set = discrete_ps, control = ctrl)
print(res)
```


#make model and save it 

```{r,eval=FALSE}
Listhe <- RandomTrainingSet(ModData3, WormIDs1110, round(length(WormIDs1110[[1]]) - 1),round(length(WormIDs1110[[2]]) - 1))
TSet <- Listhe[[1]]
PSet <- Listhe[[2]]
TSet1110 <- TSet
#Model1123 <- ksvm(as.matrix(TSet[,1:50]), as.factor(TSet[,51]),type = 'C-svc', kernel= "laplacedot",C=3,kpar = list(sigma = 1),scaled=FALSE, cross = 5)
```


# trying all the kernels

```{r,eval=FALSE}
Model1123 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "rbfdot",C=200,kpar = list(sigma = 0.002),scaled=FALSE, cross = 10)
Model1123.2 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "polydot",C=3,scaled=FALSE, cross = 5)
Model1123.3 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "vanilladot",C=3,scaled=FALSE, cross = 5)
Model1123.4 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "tanhdot",C=3,scaled=FALSE, cross = 5)
Model1123.5 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "laplacedot",C=200,kpar = list(sigma = 0.002),scaled=FALSE, cross = 5)
Model1123.6 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "besseldot",C=3,scaled=FALSE, cross = 5)
Model1123.7 <- ksvm(as.matrix(TSet1123[,1:50]), as.factor(TSet1123[,51]),type = 'C-svc', kernel= "anovadot",C=3,scaled=FALSE, cross = 5)
```


# Model 1111 on remaining sets 

```{r,eval=FALSE}
pred1 <- predict(Model1111,TSet1110[,1:50])
#sum(pred1 == ModDataTest2[,51]) / nrow(ModDataTest2)
Positive <- rownames(TSet1110[which(pred1==2),])
TP <- length(which(Positive %in% rownames(TSet1110[which(TSet1110$Factor == 2),]) ))
Negative <- rownames(TSet1110[which(pred1==1),])
TN <- length(which(Negative %in% rownames(TSet1110[which(TSet1110$Factor == 1),]) ))
 (TP + TN) / (length(Positive) + length(Negative))
# Accuracy after the filtering is  0.8921283 
TP/length(Positive)
```